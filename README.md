# Predictive Machine Learning Model Deployment using Docker and FastAPI
## Introduction
This repository provides a comprehensive solution for deploying a predictive machine learning model using Docker, FastAPI, Docker Compose, and Locust. It enables to understand the limitations of servers and test their performance under realistic production conditions.
## Features
- Docker: The project leverages Docker to ensure consistent deployment across various environments, eliminating compatibility issues and simplifying setup.
- FastAPI: FastAPI, a high-performance web framework, is utilized to build robust and scalable APIs for the machine learning model.
- Docker Compose: Docker Compose allows for easy container orchestration by defining and managing multi-container applications. It simplifies the deployment process by providing a single command to start all the necessary services.
- Locust: Locust is an open-source load testing tool used to simulate real-world user behavior and evaluate the performance of the deployed system.
- Machine Learning Model: The repository includes a sample machine learning model, ready to be deployed. However, it can be easily replaced with your own trained model by following the provided guidelines.

## Usage
1. Clone the repository to your local machine.
2. Install Docker and Docker Compose if they are not already installed.
3. Customize the machine learning model by following the provided guidelines.
4. Build and launch the Docker containers using Docker Compose.
5. Use Locust to simulate user traffic and measure the performance of the deployed system.

## License
This repository is licensed under the MIT License. Feel free to use it for both personal and commercial purposes.
## Acknowledgments

I would like to express our gratitude to the open-source community for their invaluable contributions and support.

Thank you for using this repository! I hope it simplifies the deployment of your predictive machine learning models.
