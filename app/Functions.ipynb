{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08b0510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import regex\n",
    "import demoji\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "sb.set_theme()\n",
    "import scipy.stats as st\n",
    "from underthesea import word_tokenize, pos_tag, sent_tokenize\n",
    "from pyvi import ViPosTagger, ViTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076db8fb",
   "metadata": {},
   "source": [
    "# Reduce Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d63385f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce Memory Usage\n",
    "def reduce_memory_usage(df):\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype.name\n",
    "        if ((col_type != 'datetime64[ns]') & (col_type != 'category')):\n",
    "            if (col_type != 'object'):\n",
    "                c_min = df[col].min()\n",
    "                c_max = df[col].max()\n",
    "\n",
    "                if str(col_type)[:3] == 'int':\n",
    "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                        df[col] = df[col].astype(np.int8)\n",
    "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                        df[col] = df[col].astype(np.int16)\n",
    "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                        df[col] = df[col].astype(np.int32)\n",
    "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                        df[col] = df[col].astype(np.int64)\n",
    "\n",
    "                else:\n",
    "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                        df[col] = df[col].astype(np.float16)\n",
    "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                        df[col] = df[col].astype(np.float32)\n",
    "                    else:\n",
    "                        pass\n",
    "            else:\n",
    "                df[col] = df[col].astype('category')\n",
    "    mem_usg = df.memory_usage().sum() / 1024**2 \n",
    "    print(\"Memory usage became: \",mem_usg,\" MB\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8b0fe2",
   "metadata": {},
   "source": [
    "# Exploring Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a48be43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm lọc các cột có kiểu dữ liệu continuous\n",
    "def numbers_variable(frame):\n",
    "    numbers = [col for col in frame.columns if frame.dtypes[col] != object]\n",
    "    return numbers\n",
    "\n",
    "# Hàm hiển thị dữ liệu unique của các cột continuous\n",
    "def display_numbers(frame, lst_numbers):\n",
    "    for index, num in enumerate(lst_numbers):\n",
    "        print('{}. Name var: {}, Numbers of unique: {}, Unique Value: {}'\n",
    "          .format(index + 1, num, len(frame[num].unique()), frame[num].unique()[:10]))\n",
    "        print()\n",
    "        \n",
    "# Hàm lọc các cột có kiểu dữ liệu categorical        \n",
    "def objects_variable(frame):\n",
    "    categorical = [col for col in frame.columns if frame.dtypes[col] == object]\n",
    "    return categorical\n",
    "\n",
    "# Hàm hiển thị dữ liệu unique của các cột categorical\n",
    "def display_objects(frame, lst_objects):\n",
    "    for index, cat in enumerate(lst_objects):\n",
    "        print('{}. Name obj: {}, Number of unique: {}, Unique Values: {}'\n",
    "              .format(index + 1, cat, len(frame[cat].unique()), frame[cat].unique()[:10]))\n",
    "        \n",
    "# Xây dựng các hàm phân tích dữ liệu đơn biến, hai biến đối với các thuộc tính continuous & categorcal\n",
    "\n",
    "# Hàm phân tích đơn biến thuộc tính continuos        \n",
    "def continuous_analysis(frame, var):\n",
    "    print('----- {} -----'.format(var))\n",
    "    print(frame[var].describe())\n",
    "    Q1 = np.quantile(frame[var].dropna(), 0.25)\n",
    "    Q3 = np.quantile(frame[var].dropna(), 0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = frame.loc[(frame[var] < Q1 - 1.5*IQR) | (frame[var] > Q3 + 1.5*IQR)]\n",
    "    percent_outliers = outliers.shape[0] / frame.shape[0]\n",
    "    skew = frame[var].dropna().skew()\n",
    "    kurtosis = frame[var].dropna().kurtosis()\n",
    "    median = frame[var].dropna().median()\n",
    "    miss_value = frame[var].isnull().sum()\n",
    "    variance = frame[var].var()\n",
    "    print('* Variance: {}'.format(variance))\n",
    "    print('* Median: {}'.format(median))\n",
    "    print('* Skewness: {}'.format(skew))\n",
    "    print('* Kurtosis: {}'.format(kurtosis))\n",
    "    print('* Percentage of outliers: {}'.format(percent_outliers))\n",
    "    print('* Number of missing value: {}'.format(miss_value))\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sb.distplot(frame[var].dropna())\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.boxplot(frame[var].dropna())\n",
    "    plt.show()\n",
    "    print()\n",
    "    \n",
    "# Hàm phân tích đơn biến thuộc tính categorical  \n",
    "def categorical_analysis(frame, var, ax = (10, 8)):\n",
    "    print('----- {} -----'.format(var))\n",
    "    print('Describe: ')\n",
    "    print(frame[var].describe())\n",
    "    miss_value = frame[var].isnull().sum()\n",
    "    unique_val = pd.DataFrame(frame[var].value_counts())\n",
    "    print('* Unique value: ')\n",
    "    print(unique_val)\n",
    "    print('* Mode value: {}'.format(frame[var].mode()[0]))\n",
    "    print('* Number of missing value: {}'.format(miss_value))\n",
    "    plt.figure(figsize=ax)\n",
    "    sb.barplot(data = unique_val, x = var, y = unique_val.index)\n",
    "    plt.xlabel('count of ' + var)\n",
    "    plt.show()\n",
    "    \n",
    "# Hàm phân tích hai biến có thuộc tính categorical        \n",
    "def cat_cat(frame, var1, var2, prob, stacked = False):\n",
    "    from scipy.stats import chi2_contingency\n",
    "    from scipy.stats import chi2\n",
    "    print('----- {}  vs {} -----'.format(var1, var2))\n",
    "    table = pd.crosstab(frame[var1], frame[var2])\n",
    "    print(table)\n",
    "    if stacked:\n",
    "        plt.rcParams[\"figure.figsize\"] = [12, 8]\n",
    "        table.plot(kind = 'barh', stacked = True)\n",
    "        plt.xlabel('Count')\n",
    "        plt.show()\n",
    "    else:\n",
    "        temp = table.reset_index()\n",
    "        plt.rcParams[\"figure.figsize\"] = [12, 8]\n",
    "        temp.plot(kind = 'barh', x = temp.columns[0])\n",
    "        plt.xlabel('Count')\n",
    "        plt.show()\n",
    "    stat, p_value, dof, expected = chi2_contingency(table)\n",
    "    print('----- Chi2 Hypothesis Testing -----')\n",
    "    print('P-value: {}'.format(p_value))\n",
    "    alpha = 1 - prob\n",
    "    if p_value <= alpha:\n",
    "        print('Reject H0 --> {} and {} are dependent.'.format(var1, var2))\n",
    "    else:\n",
    "        print('Accept H0 --> {} and {} are independent.'.format(var1, var2))\n",
    "        \n",
    "# Hàm phân tích hai biến có thuộc tính continuos    \n",
    "def cont_cont(frame, var1, var2):\n",
    "    print('----- {} vs {} -----'.format(var1, var2))\n",
    "    correlation = frame[var1].corr(frame[var2])\n",
    "    print('Pearson correlation between {} & {}: {}'.format(var1, var2, correlation))\n",
    "    sb.pairplot(frame[[var1, var2]].dropna(), size = 5)\n",
    "    plt.show()\n",
    "    \n",
    "# Hàm gọi tính toán Anova\n",
    "def cal_anova(*arg):\n",
    "    f, p = st.f_oneway(*arg)\n",
    "    return f, p\n",
    "\n",
    "# Hàm levene kiểm tra giả định Anova\n",
    "def cal_levene(*arg):\n",
    "    w, p_levene = st.levene(*arg)\n",
    "    return w, p_levene\n",
    "\n",
    "# Hàm xoá bỏ giá trị outlier bằng IQR\n",
    "def remove_outliers(frame, col):\n",
    "    Q1 = np.quantile(frame[col].dropna(), 0.25)\n",
    "    Q3 = np.quantile(frame[col].dropna(), 0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    clean_data = frame.loc[(frame[col] >= Q1 - 1.5*IQR) & (frame[col] <= Q3 + 1.5*IQR), col]\n",
    "    return clean_data\n",
    "\n",
    "# Hàm phân tích ảnh hưởng của biến phân loại lên biến output(continuous)\n",
    "        \n",
    "def cat_cont(frame, col, output_var, ax = (10, 6)):\n",
    "    print('----- {} vs {} -----'.format(col, output_var))\n",
    "    df = frame[[col, output_var]]\n",
    "    plt.figure(figsize=ax)\n",
    "    sb.boxplot(data = df, x = col, y = output_var)\n",
    "    if len(frame[col].unique()) > 8:\n",
    "        plt.xticks(rotation = 90)\n",
    "    df_pivot = df.pivot(columns = col, values = output_var)\n",
    "    lst = []\n",
    "    for column in df_pivot.columns:\n",
    "        lst.append(remove_outliers(df_pivot, column))\n",
    "    fvalue, pvalue = cal_anova(*lst)\n",
    "    w_levene, p_levene = cal_levene(*lst)\n",
    "    print('* --- Levene hypothesis --- *')\n",
    "    print('p_value: {}'.format(p_levene))\n",
    "    if p_levene > 0.05:\n",
    "        print('Accept H0 --> Các quần thể có phương sai bằng nhau.')\n",
    "    else:\n",
    "        print('Reject H0 --> Các quần thể có phương sai không bằng nhau.')\n",
    "    print()\n",
    "    print('* --- Anova one-way hypothesis --- *')\n",
    "    print('p_value: {}'.format(pvalue))\n",
    "    if pvalue <= 0.05:       \n",
    "        print('Reject H0 --> Có sự khác biệt đáng kể.')\n",
    "        print()\n",
    "        from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "        m_comp = pairwise_tukeyhsd(endog = df[output_var],\n",
    "                          groups = df[col],\n",
    "                          alpha = 0.05)\n",
    "        print(m_comp)\n",
    "    else:\n",
    "        print('Accept H0 --> Không có sự khác biệt đáng kể')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2372858e",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db98ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm vẽ đường ong precision & recall theo threshold    \n",
    "def plot_precision_recall_curve(model, X, y, cv):\n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    y_scores = cross_val_predict(model, X, y, cv=cv, method = 'decision_function')\n",
    "    precisions, recalls, thresholds = precision_recall_curve(y, y_scores)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(thresholds, precisions[:-1], 'g--', label = 'Precision')\n",
    "    plt.plot(thresholds, recalls[:-1], 'b--', label = 'Recall')\n",
    "    plt.legend(fontsize = 15)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Thresholds', fontsize = 15)\n",
    "    plt.title('Precision & Recall by threshold', color = 'red', fontsize = 18)\n",
    "    plt.show()\n",
    "    \n",
    "def ROC_curve_display(model, X, y, pred):\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "    yhat_proba = model.predict_proba(X)\n",
    "    print('* Area below the curve: {}'.format(round(roc_auc_score(y, yhat_proba[:, pred]), 5)))\n",
    "    print()\n",
    "    fpr, tpr, thresholds = roc_curve(y, yhat_proba[:, pred])\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.plot(fpr, tpr, marker = '.')\n",
    "    plt.xlabel('False Possitve Rate', fontsize = 15)\n",
    "    plt.ylabel('True Possitive Rate', fontsize = 15)\n",
    "    plt.title('ROC Curve of Predict class {}'.format(pred), fontsize = 18)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "# Hàm vẽ biểu đồ heatmap\n",
    "def correlation_heatmap(frame, lst_cont):\n",
    "    matrix_corr = frame[lst_cont].corr()\n",
    "    onescorr = np.ones_like(matrix_corr, bool)\n",
    "    mask = np.triu(onescorr)\n",
    "    adjusted_mask = mask[1:, : -1]\n",
    "    adjusted_matrix_corr = matrix_corr.iloc[1:, :-1]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (16, 14))\n",
    "    sb.set_theme()\n",
    "    sb.heatmap(adjusted_matrix_corr, mask = adjusted_mask, annot = True, fmt = '.2f', cmap = 'Blues', vmin = -1, vmax = 1,\n",
    "    linecolor = 'white', linewidths = 0.5);\n",
    "    y_ticks = [i for i in adjusted_matrix_corr.index]\n",
    "    x_ticks = [i for i in adjusted_matrix_corr.columns]\n",
    "    ax.set_yticklabels(y_ticks, rotation = 0, fontsize = 12)\n",
    "    ax.set_xticklabels(x_ticks, rotation = 90, fontsize = 12)\n",
    "    ax.set_title('CONTINUOUS VARIABLES CORRELATIVE MATRIX\\n', fontsize = 18, c = 'r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74214e4e",
   "metadata": {},
   "source": [
    "# Save and Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29f66f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write & save model\n",
    "def save_model(model, filename):\n",
    "    import pickle\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "    return\n",
    "\n",
    "def load_model(filename):\n",
    "    import pickle\n",
    "    with open(filename, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da013052",
   "metadata": {},
   "source": [
    "# Evaluation Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80878dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hàm đánh giá model regression trên tập test\n",
    "def eval_regression_testset(model, X_test, y_test):\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "    yhat_test = model.predict(X_test)\n",
    "    print('----- REGRESSION MODEL PERFORMANCE IN TEST-----')\n",
    "    print('* R-squared model of Test: {}'.format(round(model.score(X_test, y_test), 4)))\n",
    "    print('* MSE of output and predicted: {}'.format(mean_squared_error(y_test, yhat_test)))\n",
    "    print('* MAE of output and predicted: {}'.format(mean_absolute_error(y_test, yhat_test)))\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sb.distplot(y_test, hist = False, rug = True, kde_kws={'shade':'kde_kws'}, label = 'True label')\n",
    "    sb.distplot(model.predict(X_test), hist = False, rug = True, kde_kws={'shade':'kde_kws'}, label = 'Predicted label')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def crossval_linear_regression(model, X, y, cv):\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    from sklearn.model_selection import cross_val_predict\n",
    "    Rcross = cross_val_score(model, X, y, cv = cv)\n",
    "    MSEcross = cross_val_score(model, X, y, cv = cv, scoring = 'neg_mean_squared_error') * (-1)\n",
    "    print('----- CROSS VALIDATION OF REGRESSION MODEL -----')\n",
    "    print('* Rcross value: {}'.format(Rcross.tolist()))\n",
    "    print('* Mean of folds: {}'.format(round(Rcross.mean(), 4)))\n",
    "    print('* Std of folds: {}'.format(round(Rcross.std(), 4)))\n",
    "    print()\n",
    "    print('* MSE value: {}'.format(MSEcross.tolist()))\n",
    "    print(\"* Mean's MSE of fold: {}\".format(round(MSEcross.mean(), 4)))\n",
    "    print(\"* Std's MSE of fold: {}\".format(round(MSEcross.std(), 4)))\n",
    "    return (Rcross, MSEcross)\n",
    "\n",
    "# Hàm đánh giá hiệu suất model phân loại trên tập test   \n",
    "def eval_clf_testset(model, X, y):\n",
    "    from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "    yhat_test = model.predict(X)\n",
    "    print('----- CLASSIFICATION MODEL PREFOMANCE EVALUATION -----')\n",
    "    print('* R-squared model of Test: {}'.format(round(accuracy_score(y, yhat_test), 4)))\n",
    "    print()\n",
    "    print('* Confusion Matrix of Test: ')\n",
    "    print(confusion_matrix(y, yhat_test))\n",
    "    print()\n",
    "    print('* Classification Report of Test: ')\n",
    "    print(classification_report(y, yhat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73968821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1ece3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
